{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77162dc3-e536-4659-914c-a62c503f73e3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q1: Import and Explore the Dataset\n",
    "\n",
    "1. **Import the Dataset**:\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "\n",
    "   # Load the dataset\n",
    "   url = 'https://drive.google.com/uc?id=1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2'\n",
    "   df = pd.read_csv(url)\n",
    "   ```\n",
    "\n",
    "2. **Examine the Variables**:\n",
    "   ```python\n",
    "   # Display the first few rows of the dataset\n",
    "   print(df.head())\n",
    "\n",
    "   # Summary statistics\n",
    "   print(df.describe())\n",
    "\n",
    "   # Check for missing values\n",
    "   print(df.isnull().sum())\n",
    "   ```\n",
    "\n",
    "3. **Visualize the Data**:\n",
    "   ```python\n",
    "   import matplotlib.pyplot as plt\n",
    "   import seaborn as sns\n",
    "\n",
    "   # Distribution of each variable\n",
    "   df.hist(figsize=(12, 10))\n",
    "   plt.show()\n",
    "\n",
    "   # Pairplot to visualize relationships between features\n",
    "   sns.pairplot(df, hue='Outcome')\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### Q2: Data Preprocessing\n",
    "\n",
    "1. **Handle Missing Values**:\n",
    "   ```python\n",
    "   # Fill missing values with mean or median\n",
    "   df.fillna(df.median(), inplace=True)\n",
    "   ```\n",
    "\n",
    "2. **Remove Outliers**:\n",
    "   ```python\n",
    "   from scipy import stats\n",
    "\n",
    "   # Remove outliers using Z-score\n",
    "   df = df[(np.abs(stats.zscore(df.select_dtypes(include=['int64', 'float64']))) < 3).all(axis=1)]\n",
    "   ```\n",
    "\n",
    "3. **Transform Categorical Variables** (if applicable):\n",
    "   - In this dataset, all variables are numerical, so this step is not necessary.\n",
    "\n",
    "### Q3: Split the Dataset\n",
    "\n",
    "1. **Split Data**:\n",
    "   ```python\n",
    "   from sklearn.model_selection import train_test_split\n",
    "\n",
    "   # Features and target variable\n",
    "   X = df.drop('Outcome', axis=1)\n",
    "   y = df['Outcome']\n",
    "\n",
    "   # Split into training and test sets\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "   ```\n",
    "\n",
    "### Q4: Train a Decision Tree Model\n",
    "\n",
    "1. **Train the Model**:\n",
    "   ```python\n",
    "   from sklearn.tree import DecisionTreeClassifier\n",
    "   from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "   # Initialize the model\n",
    "   dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "   # Define hyperparameters to tune\n",
    "   param_grid = {\n",
    "       'criterion': ['gini', 'entropy'],\n",
    "       'max_depth': [None, 10, 20, 30],\n",
    "       'min_samples_split': [2, 5, 10]\n",
    "   }\n",
    "\n",
    "   # Grid search with cross-validation\n",
    "   grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "   grid_search.fit(X_train, y_train)\n",
    "\n",
    "   # Best model\n",
    "   best_model = grid_search.best_estimator_\n",
    "   ```\n",
    "\n",
    "### Q5: Evaluate the Model\n",
    "\n",
    "1. **Evaluate Performance**:\n",
    "   ```python\n",
    "   from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "   # Predict on the test set\n",
    "   y_pred = best_model.predict(X_test)\n",
    "\n",
    "   # Calculate metrics\n",
    "   accuracy = accuracy_score(y_test, y_pred)\n",
    "   precision = precision_score(y_test, y_pred)\n",
    "   recall = recall_score(y_test, y_pred)\n",
    "   f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "   print(f'Accuracy: {accuracy}')\n",
    "   print(f'Precision: {precision}')\n",
    "   print(f'Recall: {recall}')\n",
    "   print(f'F1 Score: {f1}')\n",
    "\n",
    "   # Confusion Matrix\n",
    "   cm = confusion_matrix(y_test, y_pred)\n",
    "   sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "   plt.xlabel('Predicted')\n",
    "   plt.ylabel('Actual')\n",
    "   plt.show()\n",
    "\n",
    "   # ROC Curve\n",
    "   fpr, tpr, thresholds = roc_curve(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "\n",
    "   plt.figure()\n",
    "   plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "   plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "   plt.xlim([0.0, 1.0])\n",
    "   plt.ylim([0.0, 1.05])\n",
    "   plt.xlabel('False Positive Rate')\n",
    "   plt.ylabel('True Positive Rate')\n",
    "   plt.title('Receiver Operating Characteristic')\n",
    "   plt.legend(loc='lower right')\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### Q6: Interpret the Decision Tree\n",
    "\n",
    "1. **Visualize the Tree**:\n",
    "   ```python\n",
    "   from sklearn.tree import export_text\n",
    "\n",
    "   # Print the decision tree\n",
    "   tree_rules = export_text(best_model, feature_names=list(X.columns))\n",
    "   print(tree_rules)\n",
    "   ```\n",
    "\n",
    "   - **Feature Importances**:\n",
    "     ```python\n",
    "     importances = best_model.feature_importances_\n",
    "     feature_names = X.columns\n",
    "     sorted_indices = importances.argsort()[::-1]\n",
    "     \n",
    "     plt.figure(figsize=(10, 6))\n",
    "     plt.barh(feature_names[sorted_indices], importances[sorted_indices])\n",
    "     plt.xlabel('Feature Importance')\n",
    "     plt.title('Feature Importance in Decision Tree')\n",
    "     plt.show()\n",
    "     ```\n",
    "\n",
    "### Q7: Validate the Model\n",
    "\n",
    "1. **Sensitivity Analysis**:\n",
    "   ```python\n",
    "   # Sensitivity analysis can involve testing the model with different subsets of features or perturbing input data.\n",
    "   # Example: Test with a subset of features\n",
    "   X_subset = X[['Glucose', 'BMI']]\n",
    "   X_train_subset, X_test_subset, y_train_subset, y_test_subset = train_test_split(X_subset, y, test_size=0.2, random_state=42)\n",
    "   model_subset = DecisionTreeClassifier(random_state=42)\n",
    "   model_subset.fit(X_train_subset, y_train_subset)\n",
    "   y_pred_subset = model_subset.predict(X_test_subset)\n",
    "   \n",
    "   print(f'Accuracy with subset: {accuracy_score(y_test_subset, y_pred_subset)}')\n",
    "   ```\n",
    "\n",
    "2. **Scenario Testing**:\n",
    "   ```python\n",
    "   # Modify feature values to see how predictions change\n",
    "   X_test_modified = X_test.copy()\n",
    "   X_test_modified['Glucose'] = X_test_modified['Glucose'] * 1.1\n",
    "   y_pred_modified = best_model.predict(X_test_modified)\n",
    "   \n",
    "   print(f'Accuracy with modified data: {accuracy_score(y_test, y_pred_modified)}')\n",
    "   ```\n",
    "\n",
    "### Summary\n",
    "\n",
    "By following these steps, youâ€™ll build a robust decision tree model for predicting diabetes, evaluate its performance, and ensure its reliability through validation. The steps include data exploration, preprocessing, model training, evaluation, interpretation, and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbeca66-ade1-471e-8d1e-2c887975f2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
