{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b7fe84-b663-4ea0-8b06-5224806fd56e",
   "metadata": {},
   "source": [
    "### Q1: Designing a Pipeline for Feature Engineering and Missing Value Handling\n",
    "\n",
    "To create a pipeline for handling numerical and categorical features, you can use the `Pipeline` and `ColumnTransformer` classes from `scikit-learn`. Here's a step-by-step approach:\n",
    "\n",
    "#### 1. Import Necessary Libraries\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "```\n",
    "\n",
    "#### 2. Load the Dataset\n",
    "\n",
    "```python\n",
    "# Assuming dataset is loaded into a DataFrame `df`\n",
    "df = pd.read_csv('path_to_dataset.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "```\n",
    "\n",
    "#### 3. Identify Numerical and Categorical Features\n",
    "\n",
    "```python\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "```\n",
    "\n",
    "#### 4. Create Numerical Pipeline\n",
    "\n",
    "```python\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "```\n",
    "\n",
    "#### 5. Create Categorical Pipeline\n",
    "\n",
    "```python\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "```\n",
    "\n",
    "#### 6. Combine Pipelines Using ColumnTransformer\n",
    "\n",
    "```python\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "#### 7. Feature Selection and Model Pipeline\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k='all')),  # Select important features\n",
    "    ('classifier', RandomForestClassifier())  # Use RandomForestClassifier as the final model\n",
    "])\n",
    "```\n",
    "\n",
    "#### 8. Split the Dataset\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "#### 9. Train and Evaluate the Model\n",
    "\n",
    "```python\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "```\n",
    "\n",
    "#### 10. Interpretation and Improvements\n",
    "\n",
    "- **Interpretation**: This pipeline automates preprocessing, feature selection, and model training. The accuracy score provides a measure of the model's performance on unseen data.\n",
    "- **Improvements**: Consider using different feature selection methods or hyperparameter tuning for the Random Forest model. You could also add cross-validation to better assess model performance.\n",
    "\n",
    "### Q2: Building a Pipeline with Random Forest and Logistic Regression\n",
    "\n",
    "To combine a Random Forest and Logistic Regression using a Voting Classifier, follow these steps:\n",
    "\n",
    "#### 1. Import Libraries\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "```\n",
    "\n",
    "#### 2. Load and Prepare the Iris Dataset\n",
    "\n",
    "```python\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "#### 3. Create Classifiers and Voting Classifier\n",
    "\n",
    "```python\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), ('lr', lr_clf)],\n",
    "    voting='soft'  # Use soft voting to predict probabilities\n",
    ")\n",
    "```\n",
    "\n",
    "#### 4. Train and Evaluate the Voting Classifier\n",
    "\n",
    "```python\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Voting Classifier: {accuracy:.2f}')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16157d8f-d6e3-49a3-a689-eae8cbd0d1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
