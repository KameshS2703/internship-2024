{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c5c80c-97d5-4d86-af1d-52f071843e80",
   "metadata": {},
   "source": [
    "### Steps for PCA Implementation\n",
    "\n",
    "#### 1. **Download and Load the Dataset**\n",
    "\n",
    "First, download the Wine dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Wine) and load it into a Pandas dataframe.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "columns = ['Class', 'Alcohol', 'Malic Acid', 'Ash', 'Alcalinity of Ash', 'Magnesium',\n",
    "           'Total Phenols', 'Flavanoids', 'Nonflavanoid Phenols', 'Proanthocyanins',\n",
    "           'Color Intensity', 'Hue', 'OD280/OD315 of Diluted Wines', 'Proline']\n",
    "df = pd.read_csv(url, names=columns)\n",
    "```\n",
    "\n",
    "#### 2. **Split the Dataset into Features and Target Variables**\n",
    "\n",
    "Separate the features and the target variable (Class).\n",
    "\n",
    "```python\n",
    "# Split into features and target variable\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "```\n",
    "\n",
    "#### 3. **Data Preprocessing**\n",
    "\n",
    "Perform scaling on numerical features since PCA is affected by the scale of the data.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### 4. **Implement PCA**\n",
    "\n",
    "Apply PCA using scikit-learn and determine the optimal number of principal components based on the explained variance ratio.\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "```\n",
    "\n",
    "Determine the number of principal components to retain.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(explained_variance_ratio, marker='o')\n",
    "plt.title('Explained Variance Ratio by Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Determine the number of components to retain\n",
    "optimal_components = np.argmax(explained_variance_ratio >= 0.95) + 1\n",
    "print(f'Optimal number of principal components: {optimal_components}')\n",
    "```\n",
    "\n",
    "#### 5. **Visualise PCA Results**\n",
    "\n",
    "Visualize the data in the new PCA-transformed space using scatter plots.\n",
    "\n",
    "```python\n",
    "# Apply PCA with the optimal number of components\n",
    "pca = PCA(n_components=optimal_components)\n",
    "X_pca_optimal = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Scatter plot of the first two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca_optimal[:, 0], X_pca_optimal[:, 1], c=y, cmap='viridis', edgecolor='k')\n",
    "plt.title('PCA - Scatter Plot of First Two Principal Components')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 6. **Perform Clustering Using K-Means**\n",
    "\n",
    "Apply K-Means clustering on the PCA-transformed data.\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca_optimal)\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(X_pca_optimal, clusters)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "```\n",
    "\n",
    "#### 7. **Interpret Results**\n",
    "\n",
    "- **PCA Results**: The scatter plot of the first two principal components will show how the data is spread in the new PCA-transformed space.\n",
    "- **Clustering Results**: The silhouette score will indicate how well the clusters are separated. Higher scores imply better-defined clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f011f6-796c-4d96-a645-5eaaab3063b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
